{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Reference: https://www.geeksforgeeks.org/xml-parsing-python/\n",
    "              https://python.plainenglish.io/converting-xml-to-csv-using-python-d723a3df3de1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Creating a bucket in AWS </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Using cached https://files.pythonhosted.org/packages/23/d8/3b41ce8c96dedbb449f24de21eee0742786f414fea176f984b1101154f30/boto3-1.24.84-py3-none-any.whl\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.84 in c:\\users\\asmita\\anaconda3_second\\lib\\site-packages (from boto3) (1.27.84)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\asmita\\anaconda3_second\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\asmita\\anaconda3_second\\lib\\site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\asmita\\anaconda3_second\\lib\\site-packages (from botocore<1.28.0,>=1.27.84->boto3) (1.26.12)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\asmita\\anaconda3_second\\lib\\site-packages (from botocore<1.28.0,>=1.27.84->boto3) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asmita\\anaconda3_second\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.84->boto3) (1.12.0)\n",
      "Installing collected packages: boto3\n",
      "Successfully installed boto3-1.24.84\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'WZWWCFRG0ARCKYA1',\n",
       "  'HostId': 'lkqOL7Ya9mG9l9wQQiqyyCzSFh0qGytkA7jepQR1lCuoZKljkg11siD0AlKuFRApIWsAtOVH1C4=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'lkqOL7Ya9mG9l9wQQiqyyCzSFh0qGytkA7jepQR1lCuoZKljkg11siD0AlKuFRApIWsAtOVH1C4=',\n",
       "   'x-amz-request-id': 'WZWWCFRG0ARCKYA1',\n",
       "   'date': 'Sat, 01 Oct 2022 21:22:22 GMT',\n",
       "   'location': 'http://my-dummy-bucket1.s3.amazonaws.com/',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': 'http://my-dummy-bucket1.s3.amazonaws.com/'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_bucket(Bucket = 'my-dummy-bucket1',\n",
    "                     CreateBucketConfiguration={'LocationConstraint': 'ap-south-1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> List all buckets </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "response = client.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'my-dummy-bucket1',\n",
       "  'CreationDate': datetime.datetime(2022, 10, 1, 21, 22, 23, tzinfo=tzutc())},\n",
       " {'Name': 'my-test-case-bucket',\n",
       "  'CreationDate': datetime.datetime(2022, 9, 30, 18, 49, 48, tzinfo=tzutc())}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['Buckets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Functions for connecting to bucket and pushing csv to bucket </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from io import BytesIO\n",
    "from pandas import DataFrame\n",
    "from s3_bucket import S3Bucket\n",
    "\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "def connect_to_buffer_bucket(BUCKET_NAME=os.environ.get('BUCKET_NAME', 'my-dummy-bucket1'),\n",
    "                             Access_key=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "                             Secret_key=os.environ.get('AWS_SECRET_ACCESS_KEY')):\n",
    "    '''\n",
    "    Connects to S3 bucket in order to use its functions\n",
    "    \n",
    "    Params:\n",
    "            BUCKET_NAME: name of s3 bucket\n",
    "            Access_key: Access key credentials of user to access the s3 bucket\n",
    "            Secret_key: Secret key credentials of user to access the s3 bucket\n",
    "    \n",
    "    Returns: \n",
    "            bucket\n",
    "    '''\n",
    "    bucket = None\n",
    "    \n",
    "    try:\n",
    "        bucket = S3Bucket(\n",
    "            bucket=BUCKET_NAME,\n",
    "            access_key_id=Access_key,\n",
    "            secret_access_key=Secret_key\n",
    "        )\n",
    "        logging.info(f'Successfully connected to the bucket \"{BUCKET_NAME}\"')\n",
    "        return bucket\n",
    "    except Exception as e:\n",
    "        logging.info(\n",
    "            f'{e}\\nError connecting to bucket \"{BUCKET_NAME}\": Please check the credentials again.'\n",
    "        )\n",
    "\n",
    "\n",
    "def push_csv_to_buffer_bucket(bucket: S3Bucket, dataframe: DataFrame, rel_path: str):\n",
    "    '''\n",
    "    Push the generated CSV to s3 bucket\n",
    "    \n",
    "    Params:\n",
    "           bucket: name of imported class from module\n",
    "           dataframe: dataframe generated through code\n",
    "           rel_path: path of the directory the CSV will get stored\n",
    "           \n",
    "    Return:\n",
    "           Message on successfully pushing CSV to bucket, if not raises error\n",
    "           \n",
    "    '''\n",
    "    try:\n",
    "        buffer = BytesIO(\n",
    "            bytes(\n",
    "                dataframe.to_csv(index=True, header=True),\n",
    "                encoding=\"utf-8\",\n",
    "            )\n",
    "        )\n",
    "        bucket.upload_file(fileobj=buffer, key=rel_path)\n",
    "        logging.info(f'Successfully pushed the csv file to \"{rel_path}\"')\n",
    "    except Exception as e:\n",
    "        logging.info(f'{e}\\nError occured while pushing file to bucket path \"{rel_path}\"')\n",
    "        logging.info(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Installing Selenium package</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Asmita\\Anaconda3_second\n",
      "\n",
      "  added / updated specs:\n",
      "    - selenium\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  anaconda                                    custom-py37_1 --> 2019.03-py37_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  ca-certificates                     2022.07.19-haa95532_0 --> 2019.1.23-0\n",
      "  certifi                          2022.9.14-py37haa95532_0 --> 2019.3.9-py37_0\n",
      "  openssl                                 1.1.1c-he774522_1 --> 1.1.1b-he774522_1\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asmita\\Anaconda3_second\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Importing necessary libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asmita\\Anaconda3_second\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.etree.ElementTree as Xet\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pydoc\n",
    "import zipfile\n",
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Got the data in xml format from given URL\n",
      "INFO:root:Parsed and got the files whose file_type is DLTINS\n",
      "INFO:root:Extracted the zipped files in a folder\n",
      "INFO:root:Extracted the zipped files in a folder\n",
      "INFO:root:Extracted the zipped files in a folder\n",
      "INFO:root:Extracted the zipped files in a folder\n",
      "INFO:root:Successfully connected to the bucket \"my-dummy-bucket1\"\n",
      "INFO:root:Successfully pushed the csv file to \"my-dummy-bucket1/outputs/DLTINS_20210117_01of01_2022-10-04.csv\"\n",
      "INFO:root:Successfully connected to the bucket \"my-dummy-bucket1\"\n",
      "INFO:root:Successfully pushed the csv file to \"my-dummy-bucket1/outputs/DLTINS_20210118_01of01_2022-10-04.csv\"\n",
      "INFO:root:Successfully connected to the bucket \"my-dummy-bucket1\"\n",
      "INFO:root:Successfully pushed the csv file to \"my-dummy-bucket1/outputs/DLTINS_20210119_01of02_2022-10-04.csv\"\n",
      "INFO:root:Successfully connected to the bucket \"my-dummy-bucket1\"\n",
      "INFO:root:Successfully pushed the csv file to \"my-dummy-bucket1/outputs/DLTINS_20210119_02of02_2022-10-04.csv\"\n",
      "INFO:root:Process finished --- 431.9912061691284 seconds ---\n"
     ]
    }
   ],
   "source": [
    "class CSV_conversion:\n",
    "    def __init__(self, url):\n",
    "        '''\n",
    "             url: url given in main question\n",
    "        '''\n",
    "        self.url = url\n",
    "        \n",
    "    def get_xml(self):\n",
    "        '''\n",
    "            Save the data of provided link in a xml file\n",
    "                  \n",
    "            Return: \n",
    "                  Output in the form of .xml file is generated\n",
    "        '''\n",
    "        resp = requests.get(self.url)\n",
    "  \n",
    "        # saving the xml file\n",
    "        with open('my_file.xml', 'wb') as f:\n",
    "            f.write(resp.content)\n",
    "        logging.info(\"Got the data in xml format from given URL\")\n",
    "          \n",
    "  \n",
    "    def parseXML(self, xmlfile):\n",
    "        '''\n",
    "             Traverse xml file to fetch the links to DLTINS files\n",
    "             \n",
    "             Params:\n",
    "                     xmlfile: xml file generated in previous step\n",
    "             Return:\n",
    "                     list of downloadable links\n",
    "        '''\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        prefs = {'download.default_directory' : 'C:\\\\Users\\\\Asmita\\\\AAIC_ASSIGNMENTS\\\\Assignment\\\\raw_directory'}\n",
    "        chrome_options.add_experimental_option('prefs', prefs)\n",
    "  \n",
    "        wd = webdriver.Chrome(executable_path= r'C:/Users/Asmita/chromedriver_win32/chromedriver.exe',options=chrome_options)\n",
    "    \n",
    "        # create element tree object\n",
    "        tree = ET.parse(xmlfile)\n",
    "\n",
    "        # get root element\n",
    "        root = tree.getroot()\n",
    "\n",
    "      \n",
    "        lst = []\n",
    "        for item in root.iter('str'):\n",
    "            if item.text.endswith('zip'):\n",
    "                lst.append(item.text)\n",
    "        new_lst = []\n",
    "        for i in range(len(lst)):\n",
    "            if i%2==0:\n",
    "                wd.get(lst[i])\n",
    "            else:\n",
    "                new_lst.append(lst[i])\n",
    "        logging.info(\"Parsed and got the files whose file_type is DLTINS\")\n",
    "        return new_lst\n",
    "  \n",
    "    def unzip_files(self, item, path):\n",
    "        '''\n",
    "            Extract the contents of the zipped files in a specific folder\n",
    "            \n",
    "            Params:\n",
    "                    item: link of downloadable zip file\n",
    "                    path: folder path where the zipped files are located\n",
    "                \n",
    "            Return:\n",
    "                    A folder is generated with the xml files that needs to be converted to csv\n",
    "        '''\n",
    "        time.sleep(30)\n",
    "        file = path + item\n",
    "        with zipfile.ZipFile(file,\"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"target_dir\")\n",
    "        logging.info(\"Extracted the zipped files in a folder\")\n",
    "\n",
    "    def df_contents(self, i, key1, ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr):\n",
    "        '''\n",
    "             Append the values of specific dictionary key to a list\n",
    "             \n",
    "             Params:\n",
    "                     i:               nested dictionary value \n",
    "                     key1:            key of dictionary\n",
    "                     ID:              list of IDs elements\n",
    "                     FullNm:          list of FullNm elements\n",
    "                     ClassfctnTp:     list of ClassfctnTp elements\n",
    "                     CmmdtyDerivInd:  list of CmmdtyDerivInd elements\n",
    "                     NtnlCcy:         list of NtnlCcy elements\n",
    "                     Issr:            list of Issr elements\n",
    "        '''\n",
    "        if key1 in i.keys():\n",
    "            for k, v in i[key1]['FinInstrmGnlAttrbts'].items():\n",
    "                if k == 'Id':\n",
    "                    ID.append(v)\n",
    "                elif k == 'FullNm':\n",
    "                    FullNm.append(v)\n",
    "                elif k == 'ClssfctnTp':\n",
    "                    ClssfctnTp.append(v)\n",
    "                elif k == 'CmmdtyDerivInd':\n",
    "                    CmmdtyDerivInd.append(v)\n",
    "                elif k == 'NtnlCcy':\n",
    "                    NtnlCcy.append(v)\n",
    "                else:\n",
    "                    pass\n",
    "                    Issr.append(i[key1]['Issr'])\n",
    "        return ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr\n",
    "  \n",
    "    def savetoCSV(self, item):\n",
    "        '''\n",
    "            Convert contents of xml file to csv and push to bucket\n",
    "            \n",
    "            Params:\n",
    "                    item: name of the .xml file\n",
    "                \n",
    "            Return:\n",
    "                    Message of successfully pushing csv to bucket else raises error\n",
    "        '''\n",
    "        \n",
    "        bucket = connect_to_buffer_bucket()\n",
    "        path = 'my-dummy-bucket1/outputs/' + item.split(\".\")[0] + '_' + str(date.today()) + '.csv'\n",
    "\n",
    "        file_path = 'C:\\\\Users\\\\Asmita\\\\AAIC_ASSIGNMENTS\\\\Assignment\\\\target_dir\\\\' + item\n",
    "        with open(file_path, 'r', encoding=\"utf8\") as file:\n",
    "            filedata = file.read()\n",
    "    \n",
    "        # Converting xml to python dictionary (ordered dict)    \n",
    "        data_dict = xmltodict.parse(filedata)\n",
    "\n",
    "        lst = data_dict['BizData']['Pyld']['Document']['FinInstrmRptgRefDataDltaRpt']['FinInstrm']\n",
    "\n",
    "        ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr = ([] for i in range(6))\n",
    "        for i in lst:\n",
    "            if 'TermntdRcrd' in i.keys():\n",
    "                ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr = self.df_contents(i, 'TermntdRcrd',ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr)\n",
    "            elif 'ModfdRcrd' in i.keys():\n",
    "                ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr = self.df_contents(i, 'ModfdRcrd',ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr)\n",
    "            elif 'NewRcrd' in i.keys():\n",
    "                ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr = self.df_contents(i, 'NewRcrd',ID, FullNm, ClssfctnTp, CmmdtyDerivInd, NtnlCcy, Issr)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        data = pd.DataFrame({'FinInstrmGnlAttrbts.Id': ID, 'FinInstrmGnlAttrbts.FullNm': FullNm, 'FinInstrmGnlAttrbts.ClssfctnTp' :\tClssfctnTp, 'FinInstrmGnlAttrbts.CmmdtyDerivInd': CmmdtyDerivInd, 'FinInstrmGnlAttrbts.NtnlCcy': NtnlCcy, 'Issr': Issr})\n",
    "    \n",
    "        push_csv_to_buffer_bucket(bucket, data, path)\n",
    "        file.close()\n",
    "      \n",
    "    def main(self):\n",
    "        '''\n",
    "            main function that gives call to all internal functions to get to the neccessary output\n",
    "            \n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        self.get_xml()\n",
    "        \n",
    "        if not os.path.exists('raw_directory'):\n",
    "            os.makedirs('raw_directory')\n",
    "  \n",
    "        # parse xml file\n",
    "        result = self.parseXML('my_file.xml')\n",
    "\n",
    "        raw_directory_path = 'C:\\\\Users\\\\Asmita\\\\AAIC_ASSIGNMENTS\\\\Assignment\\\\raw_directory\\\\'\n",
    "        \n",
    "        # #unzip dowmloaded files\n",
    "        for item in result:\n",
    "            self.unzip_files(item, raw_directory_path)\n",
    "\n",
    "        # save csv to bucket\n",
    "        for files in os.listdir(\"target_dir\"):\n",
    "            if files.endswith('.xml'):\n",
    "                self.savetoCSV(files)\n",
    "        logging.info(\"Process finished --- %s seconds ---\" % (time.time() - start_time))\n",
    "      \n",
    "      \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # calling main function\n",
    "    obj = CSV_conversion('https://registers.esma.europa.eu/solr/esma_registers_firds_files/select?q=*&fq=publication_date:%5B2021-01-17T00:00:00Z+TO+2021-01-19T23:59:59Z%5D&wt=xml&indent=true&start=0&rows=100')\n",
    "    obj.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
